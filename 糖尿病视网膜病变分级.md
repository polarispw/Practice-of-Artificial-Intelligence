## 任务三：糖尿病视网膜病变分级

### 模型简述

这一任务在许多深度学习的比赛中都曾出现，我们在查阅资料时发现，大多数效果较好的模型都是采用了Efficient Net，也有一部分是结合了Res-Net、Inception、Mobile Net做集成学习，但是后者的训练代价是很大的，而且效果也没有特别明显的突破。所以我们最终还是决定选用efficient net v2来做这个分类任务。

Efficient Net的作者通过调整网络的宽度、深度以及输入网络的分辨率来提升网络的性能，最终得到了一系列适用于不同分表率的模型。但是第一代Efficient Net在训练时却很耗费显存并且收敛速度也没有达到理想值，因此作者对第一代的网络做了一些改动，使用Fused-MBConv替换掉了浅层的MBConv，并且设计了渐进式的学习策略来减少训练时间。



论文地址: https://arxiv.org/abs/2104.00298

代码地址: https://github.com/google/automl/tree/master/efficientnetv2



**这里可以加一下模型的架构图和具体的细节图**



### 训练流程

#### 数据准备：（[这是处理好的数据集->模型训练](https://drive.google.com/drive/folders/1T54Cn1Y98KO_SauicJ22tQQ20ZGFlTK3?usp=sharing)）

我们拿到手的原始数据集内容是一千张眼底图像和对应的边界框标签数据。

```html
眼底分级
|---train（图片）
|---Mess1_annotation_train.csv（标注数据）
```

|      |         image          | quality | type | Retinopathy_grade | Risk_of_macular_edema |
| :--: | :--------------------: | :-----: | :--: | :---------------: | :-------------------: |
|  0   | 20051019_38557_0100_PP |    0    | _000 |         3         |           1           |
|  1   | 20051020_43808_0100_PP |    1    | _101 |         0         |           0           |
|  2   | 20051020_43832_0100_PP |    2    | _111 |         1         |           0           |
|  3   | 20051020_43882_0100_PP |    2    | _111 |         2         |           0           |
| ...  |          ...           |   ...   | ...  |        ...        |          ...          |

原始数据集中各等级的图片是混在一起的，我们要根据表格的`retinopathy_grade`列将它们分别存到四个文件夹中。

将项目和数据文件按照如下路径设置并运行`preparing_data.py`即可。

```
本地项目的文件目录部分内容如下（下载的处理好的数据集要放在此文件夹中）：
efficientnetV2_for_classification
|---weights
|---runs
|---save_weights
|---estimate_info
|---datasets_for_efficientnetV2
    |---0
    |---1
    |---2
    |---3
|---train.py
|---predict.py
|---preparing_data.py
|---pre_efficientnetv2-s.pth
```



1000张数据集样本类别情况:

| 病变级别 | 类别数量 |
| -------- | -------- |
| 0        | 461      |
| 1        | 136      |
| 2        | 207      |
| 3        | 196      |

我们观察到，样本存在一定的不平衡。



**数据扩充:**

对于四分类而言，我们需要更多的数据进行训练。

Kaggle APTOS 2019 Blindness Detection 竞赛数据集:

[APTOS 2019 Blindness Detection | Kaggle](https://www.kaggle.com/competitions/aptos2019-blindness-detection/data)

该数据集共有五类病变级别，由于我们进行四分类，我们将该数据集的第3类和第4类合并为第三类。

训练集: 3662张图片

| 病变级别 | 类别数量 |
| -------- | -------- |
| 0        | 1805     |
| 1        | 370      |
| 2        | 999      |
| 3        | 488      |

测试集: 1982张图片, 无标签。



高质量验证集:

  我们找到了一个约200张图片的和最初一千张图片相似的四个病变级别的数据集，图片质量较高，我们将其作为检验模型性能的重要测试集。

| 病变级别 | 类别数量 |
| -------- | -------- |
| 0        | 85       |
| 1        | 17       |
| 2        | 40       |
| 3        | 58       |



#### 训练和优化

按照文件目录设置好以后，在`train.py`的参数列表中修改相应路径，或直接在命令行中输入下面的命令即可进行训练。

```python
python train.py --data-path datasets_for_efficientnetV2 --epochs 30 --batch-size 8 --weights pre_efficientnetv2-s.pth --freeze-layers False
```

模型的权重会保存在`weights`文件夹中，并且会将训练过程中错分类的情况保存在`estimate_info`中

```python
estimate_info的部分内容
[epoch(train): 0 ]
precision: 0.878788, 0.721649, 0.781250, 0.912162
recall: 0.943089, 0.642202, 0.753012, 0.859873
err_name_list [图片名, 原始标签, 错判标签]:
path: 1/20051202_38513_0400_PP.png    1    3
path: 2/20051202_55484_0400_PP.png    2    3
path: 3/20051020_44598_0100_PP.png    3    2
...
```



**训练细节**

**解决类别不平衡问题**



```

```



**数据预处理**

- 基于眼球的resize

- 特征增强

- 去除眼球周围部分

| 正常图像                                                     | 预处理图像                                                   |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| <img src="doc\classification_normal_0.png" style="zoom:33%;" /> | <img src="doc\classfication_transform_0.png" style="zoom: 33%;" /> |
| <img src="doc\classification_normal_3.png" style="zoom:33%;" /> | <img src="doc\classification_transform_3.png" style="zoom:33%;" /> |

实验结果表明， 数据预处理几乎没有影响， 说明我们的网络学习能力较强，成功学习到了预处理凸显的图像特征。 



**数据增强**



```

```



**利用kaggle测试集数据**

​	我们首先利用kaggle训练集 + 初始的一千张图片训练出模型， 对kaggle的test集进行预测。再将预测结果中某一类的置信度大于70%的图片打上该类的标签，归为实际的训练集。

最终我们的数据集为:



| 病变级别 | 类别数量 |
| -------- | -------- |
| 0        |          |
| 1        |          |
| 2        |          |
| 3        |          |





### 实验和结果分析

**预训练参数**

我们主要使用EfficientNetV2-s 和 EfficientNetV2-m 预训练参数。

EfficientNetV2-S 的配置是在baseline的基础上采用了width倍率因子1.4， depth倍率因子1.8得到的（这两个倍率因子是EfficientNetV1-B4中采用的）。

```
v2_s_block = [  # about base * (width1.4, depth1.8)
    'r2_k3_s1_e1_i24_o24_c1',
    'r4_k3_s2_e4_i24_o48_c1',
    'r4_k3_s2_e4_i48_o64_c1',
    'r6_k3_s2_e4_i64_o128_se0.25',
    'r9_k3_s1_e6_i128_o160_se0.25',
    'r15_k3_s2_e6_i160_o256_se0.25',
]
```



EfficientNetV2-M 的配置是在baseline的基础上采用了width倍率因子1.6， depth倍率因子2.2得到的（这两个倍率因子是EfficientNetV1-B5中采用的）。

```
v2_m_block = [  # about base * (width1.6, depth2.2)
    'r3_k3_s1_e1_i24_o24_c1',
    'r5_k3_s2_e4_i24_o48_c1',
    'r5_k3_s2_e4_i48_o80_c1',
    'r7_k3_s2_e4_i80_o160_se0.25',
    'r14_k3_s1_e6_i160_o176_se0.25',
    'r18_k3_s2_e6_i176_o304_se0.25',
    'r5_k3_s1_e6_i304_o512_se0.25',
]
```



**训练过程**

超参设置:

| 超参       | 数据 |
| ---------- | ---- |
| epoches    |      |
| batch-size |      |
| lr         |      |
| lrf        |      |
| optimizer  |      |
| scheduler  |      |
| weights    |      |



训练结果:

| 数据       |                          图片                          |
| ---------- | :----------------------------------------------------: |
| lr         |    <img src="doc\分类lr.png" style="zoom: 50%;" />     |
| train_acc  | <img src="doc\分类train_acc.png" style="zoom:50%;" />  |
| train_loss | <img src="doc\分类train_loss.png" style="zoom:50%;" /> |
| val_acc    |  <img src="doc\分类val_acc.png" style="zoom:50%;" />   |
| val_loss   | <img src="doc\分类train_loss.png" style="zoom:50%;" /> |



调整预训练:

超参设置:

| 超参       | 数据 |
| ---------- | ---- |
| epoches    |      |
| batch-size |      |
| lr         |      |
| lrf        |      |
| optimizer  |      |
| scheduler  |      |
| weights    |      |



结果:

